{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kayaisacat/IAI5101_Assignment2/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "36ae58c4",
      "metadata": {},
      "source": [
        "# Part A: Supervised Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf19dbe",
      "metadata": {
        "id": "3cf19dbe"
      },
      "outputs": [],
      "source": [
        "# library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import xgboost as xgb\n",
        "import tensorflow\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KcN5pR-z9ouG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcN5pR-z9ouG",
        "outputId": "4d5d051a-4b59-408e-d401-0b56aa5204b4"
      },
      "outputs": [],
      "source": [
        "# using colab from drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c245d5b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c245d5b9",
        "outputId": "fdae2622-2863-4362-999e-782016f2e3e1"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "#df=pd.read_csv('drive/My Drive/Colab Notebooks/concrete.csv')\n",
        "df=pd.read_csv('/Users/yuting/Desktop/Assignment2/concrete.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7bcdb36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "c7bcdb36",
        "outputId": "3ee03fee-4cb0-4adb-b08a-cad201f605ff"
      },
      "outputs": [],
      "source": [
        "# check the initial five records\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a53f2a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a53f2a8",
        "outputId": "d937e4ad-0874-403a-9fb3-abcdfe4f0415"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "91a6274d",
      "metadata": {
        "id": "91a6274d"
      },
      "source": [
        "## I. EDA :"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ecb30403",
      "metadata": {
        "id": "ecb30403"
      },
      "source": [
        "### Univariate Analysis: \n",
        "#### 1. Build a histogram to show the distribution and central values of all the variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fea3e7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up the figure\n",
        "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(16, 12))\n",
        "\n",
        "# Loop through each variable and create a histogram\n",
        "for i, var in enumerate(df.columns):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "    sns.histplot(data=df[var], bins=10, kde=True, ax=axs[row][col])\n",
        "    axs[row][col].set_title(var)\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get central values of all variables\n",
        "central_values = df.describe().loc[['mean', '50%'], :]\n",
        "central_values = central_values.T\n",
        "print(central_values)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ca1ccfea",
      "metadata": {
        "id": "ca1ccfea"
      },
      "source": [
        "#### 2. Use a boxplot to determine if there are outliers in the variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01a9e64b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up the figure\n",
        "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(16, 12))\n",
        "\n",
        "# Loop through each variable and create a boxplot\n",
        "for i, var in enumerate(df.columns):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "    sns.boxplot(x=df[var], ax=axs[row][col])\n",
        "    axs[row][col].set_title(var)\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12abb343",
      "metadata": {
        "id": "12abb343"
      },
      "source": [
        "Blast Furnace Slag, Water , Super plasticizer, Fine Aggregate, Age, Compressive Strength\n",
        "have outliners in dataset. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9adeb9a9",
      "metadata": {
        "id": "9adeb9a9"
      },
      "source": [
        "### Multivariate Analysis:\n",
        "#### 1. Use a pair plot to determine the relationship and degree of relation between independent variables and between independent variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8e29d5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f8e29d5a",
        "outputId": "0204286d-2ec5-4ef1-f0ff-2abbbd8feff3"
      },
      "outputs": [],
      "source": [
        "# draw matrix\n",
        "scatter_matrix(df,figsize=(20,20));"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f2860dc2",
      "metadata": {
        "id": "f2860dc2"
      },
      "source": [
        "#### 2. Use a heatmap to check for correlation between predictor variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e6c7c3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e6c7c3e",
        "outputId": "8e2515b5-9668-434d-b791-0e22b8bce657"
      },
      "outputs": [],
      "source": [
        "corr = df.corr()\n",
        "corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c82b0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "d9c82b0f",
        "outputId": "31f7403d-7038-4c34-e311-2637631ac816"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,12))\n",
        "sns.heatmap(corr, annot = True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b157289a",
      "metadata": {
        "id": "b157289a"
      },
      "source": [
        "## II. Feature Engineering"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "53509375",
      "metadata": {
        "id": "53509375"
      },
      "source": [
        "### Ensure data is in the correct format for downstream processes\n",
        "#### 1. Check for duplicates & missing values and drop, if present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eec866c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eec866c",
        "outputId": "3ccfcb00-9f5e-45ed-a131-5978ff83ea8b"
      },
      "outputs": [],
      "source": [
        "# check for missing values\n",
        "print(\"Missing values:\\n\", df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d3140a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6d3140a",
        "outputId": "75017ef1-e23f-4fc7-8616-271af786e7cd"
      },
      "outputs": [],
      "source": [
        "# check for deplicate values\n",
        "print(\"Duplicates:\\n\", df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1679118",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1679118",
        "outputId": "4d639e00-d6de-47c2-808a-3d049fc73f4e"
      },
      "outputs": [],
      "source": [
        "# the shape of dataframe\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35bf6e02",
      "metadata": {
        "id": "35bf6e02"
      },
      "outputs": [],
      "source": [
        "# drop duplicates\n",
        "df = df.drop_duplicates()\n",
        "# check the data shape\n",
        "df.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c0b98122",
      "metadata": {},
      "source": [
        "There are 0 missing value and 25 duplicate values in the concrete dataset,  after drop the total data changed from 1030 rows to 1005 rows."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "76d863a8",
      "metadata": {
        "id": "76d863a8"
      },
      "source": [
        "#### 2. Remove possible outliners in the dataset\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1c793321",
      "metadata": {},
      "source": [
        "I define the outliners as greater than 75% quartile add the 1.5 Interquatrile range and less than 25% quartile subtract the 1.5 Interquatrile range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a6346f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop the outlier observations using quartile\n",
        "q1 = df.quantile(0.25)\n",
        "q3 = df.quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "lower_threshold = q1 - (1.5 * iqr)\n",
        "upper_threshold = q3 + (1.5 * iqr)\n",
        "\n",
        "# Identify the outlier observations\n",
        "outliers_low = (df < lower_threshold)\n",
        "outliers_high = (df > upper_threshold)\n",
        "outliers = outliers_low | outliers_high\n",
        "\n",
        "# Remove the outlier observations\n",
        "df = df[~outliers.any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc952d64",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the outliers have been removed\n",
        "# Set up the figure\n",
        "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(16, 12))\n",
        "\n",
        "# Loop through each variable and create a boxplot\n",
        "for i, var in enumerate(df.columns):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "    sns.boxplot(x=df[var], ax=axs[row][col])\n",
        "    axs[row][col].set_title(var)\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c201888a",
      "metadata": {},
      "source": [
        "As you can see from boxplots, unreasonable outliers have been removed. For example, there are four values ​​in age that are over 150 years old. Although there are outliers in the above image, they are all within a reasonable range, so there is no need to deal with them again."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cca1c469",
      "metadata": {
        "id": "cca1c469"
      },
      "source": [
        "#### 3. Check for zero in the dataset and impute with the mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ecae4ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Frequency of negative or zero is:\\n', (df <= 0).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51a2be6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for zeros in the dataset and impute with the mean\n",
        "imp_mean = SimpleImputer(missing_values=0, strategy='mean')\n",
        "df = pd.DataFrame(imp_mean.fit_transform(df), columns=df.columns)\n",
        "print('Frequency of negative or zero is:\\n', (df <= 0).sum())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "77f5e22f",
      "metadata": {},
      "source": [
        "#### 4. Check for class imblance and handle, if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b2fb6c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# The target variable is CompressiveStrength\n",
        "# so we will check for class imblance and handle by examining the distribution \n",
        "sns.histplot(df['CompressiveStrength'], kde=True)\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "75d12fef",
      "metadata": {},
      "source": [
        "From the histgoram, we can see that the distribution is not heavily skewed towards one class, so we can say that there is no class imblance."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "15927b89",
      "metadata": {},
      "source": [
        "#### 5. Scale the data using a standard scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "985fb473",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the StandardScaler \n",
        "scaler = StandardScaler() \n",
        "# To scale data sicne all data are not binary\n",
        "df_scaled = scaler.fit_transform(df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d9af2716",
      "metadata": {},
      "source": [
        "## III. Model Development I\n",
        "### Ensemble Method:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "64e8a411",
      "metadata": {},
      "source": [
        "#### 1. Split dataset into train (70%) and test (30%) and build predictive models to determine the strength of concrete using the following techniques: K-Nearest Neighbor Regressor, Random Forest, and XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887dbae9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and test sets\n",
        "X = df.drop(['CompressiveStrength'], axis=1)\n",
        "y = df['CompressiveStrength']\n",
        "\n",
        "# set seed for reproducability\n",
        "np.random.seed(100)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "print(X_train.shape,y_train.shape)\n",
        "\n",
        "# Scale the data using a standard scaler\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac1564f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# K-Nearest Neighbor Regressor\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "knn_score = knn.score(X_test_scaled, y_test)\n",
        "print('K-Nearest Neighbor Regressor Score:', knn_score)\n",
        "\n",
        "# Random Forest Regressor\n",
        "rf = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "rf_score = rf.score(X_test_scaled, y_test)\n",
        "print(\"Random Forest Regressor score:\", rf_score)\n",
        "\n",
        "# XGBoost Regressor\n",
        "xgb = xgb.XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\n",
        "xgb.fit(X_train_scaled, y_train)\n",
        "xgb_score = xgb.score(X_test_scaled, y_test)\n",
        "print(\"XGBoost Regressor score:\", xgb_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "131fdda1",
      "metadata": {},
      "source": [
        "We got the evaluation score of each model, and we can see that the XGBoost is better perfomance than others. The R-squared is 0.93, which means XGBoost has a great prediction."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6d8e3d35",
      "metadata": {},
      "source": [
        "#### 2. Use a voting regressor to predict the values for the ensemble of heterogeneous models above (K-Nearest Neighbor Regressor, Random Forest & xGBoost)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd387ef1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the voting regressor\n",
        "voting_regressor = VotingRegressor([('knn', knn), ('rf', rf), ('xgb', xgb)])\n",
        "\n",
        "# Train the voting regressor\n",
        "voting_regressor.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = voting_regressor.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the performance of the voting regressor\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Evaluate the performance of the voting regressor\n",
        "score = voting_regressor.score(X_test_scaled, y_test)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R-squared:\", r2)\n",
        "print(\"Score:\", score)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6f12bb5c",
      "metadata": {},
      "source": [
        "The ensemble of heterogeneous models have a good predition, and the evaluation of the voting regressor has a great performance which R-squared equals to 0.9."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6e604e36",
      "metadata": {},
      "source": [
        "## IV. Model Development II\n",
        "### Deep Learning:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0c927cc8",
      "metadata": {},
      "source": [
        "#### 1. Split dataset into train (70%) and test (30%) and train a deep neural network using Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63d75e04",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "85ae95a3",
      "metadata": {},
      "source": [
        "#### 2. Try to improve the model by changing the activation function or dropout rate. What effects does any of these have on the result?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4506cd40",
      "metadata": {},
      "source": [
        "## V. Model Comparsion, Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fc0fc6ae",
      "metadata": {},
      "source": [
        "# Part B: Unsupervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40028556",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
